POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=loresmith
POSTGRES_USER=loresmithuser
POSTGRES_PASSWORD=your_postgres_password_here

JWT_SECRET=replace_with_a_strong_random_secret

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# AI PROVIDER CONFIGURATION

# Choose between local (free) or cloud (paid) AI generation
# 
# Option 1: Local Generation (free, slower, runs on your machine)
# - Set AI_PROVIDER=local
# - Requires Ollama installed: https://ollama.com/download
# - Download a model: ollama pull llama3.1:8b
# - No API costs, unlimited usage
# - Runs on your GPU/CPU
#
# Option 2: Cloud Generation (paid, faster, uses OpenRouter API)
# - Set AI_PROVIDER=openrouter
# - Requires OpenRouter API key: https://openrouter.ai/
# - Costs money per request (GPT-4: ~$0.13 per character)
# - Higher quality, faster responses

# AI Provider: "local" for Ollama (free) or "openrouter" for cloud (paid)
AI_PROVIDER=local

# OpenRouter API Key (only needed if AI_PROVIDER=openrouter)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Local Model Configuration (only used if AI_PROVIDER=local)
# Popular models: llama3.1:8b, mistral:7b, gemma2:9b
LOCAL_MODEL=llama3.1:8b

# Ollama API URL (default works for local installation)
# Use http://host.docker.internal:11434 when running in Docker
# Use http://localhost:11434 when running outside Docker
OLLAMA_URL=http://host.docker.internal:11434


